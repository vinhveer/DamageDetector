# ch·∫°y ƒë·ªÉ l√†m h√¨nh t∆∞·ªùng c√≥ h∆∞ h·ªèng. Ch·∫°y ·ªü ch·∫ø ƒë·ªô T ƒë·ªÉ c√≥ h√¨nh c√≥ khung ƒë√≥ng c√°c h∆∞ h·ªèng
# ch·∫°y ·ªü ch·∫ø ƒë·ªô M ƒë·ªÉ ch·ªâ c√≥ segmentation m√† kh√¥ng ph√¢n lo·∫°i h∆∞ h·ªèng

import os
import cv2
import numpy as np
import torch
from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator

# ====== C·∫§U H√åNH ======
sam_checkpoint = r"sam_vit_b_01ec64.pth"
model_type = "vit_b"
image_path = r"D:\Reseach\19_NCS\1 SAM GroundDINO\pics\wall.JPG"

# Th∆∞ m·ª•c l∆∞u m·∫∑c ƒë·ªãnh: GDINO_SAM_<t√™n ·∫£nh> c·∫°nh file ·∫£nh
IMG_DIR = os.path.dirname(image_path)
IMG_NAME = os.path.splitext(os.path.basename(image_path))[0]  # => "columnCrack"
DEFAULT_SAVE_DIR = os.path.join(IMG_DIR, f"GDINO_SAM_{IMG_NAME}")

# GroundingDINO (Tiny cho CPU/GPU trung b√¨nh; c√≥ th·ªÉ ƒë·ªïi sang 'IDEA-Research/grounding-dino-base')
# GDINO_MODEL_ID = "IDEA-Research/grounding-dino-tiny"
GDINO_MODEL_ID = "IDEA-Research/grounding-dino-base"

# Danh s√°ch prompt m·∫∑c ƒë·ªãnh
TEXT_QUERIES = [
    # "bridge","crack", "mold", "water"
    # "bridge", "bridge beam","bridge girder", "beam", "girder"
    "crack", "mold", "stain", "spall", "damage"
]

# Ng∆∞·ª°ng cho GroundingDINO
BOX_THRESHOLD = 0.2     # l·ªçc box y·∫øu
TEXT_THRESHOLD = 0.2    # l·ªçc logit vƒÉn b·∫£n y·∫øu

# ====== LOAD ·∫¢NH ======
bgr = cv2.imread(image_path)
if bgr is None:
    raise FileNotFoundError(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {image_path}")
img = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)

# ====== THI·∫æT B·ªä ======
device = "cpu"
print("Device:", device)

# ====== LOAD SAM ======
if not os.path.isfile(sam_checkpoint):
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y checkpoint: {sam_checkpoint}")

sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
sam.to(device=device)

predictor = SamPredictor(sam)
predictor.set_image(img)

# ====== SAM AUTO GENERATOR ======
def make_mask_generator(profile="QUALITY"):
    if profile.upper() == "QUALITY":
        return SamAutomaticMaskGenerator(
            model=sam,
            points_per_side=24,
            points_per_batch=64,
            pred_iou_thresh=0.92,
            stability_score_thresh=0.92,
            stability_score_offset=0.95,
            box_nms_thresh=0.7,
            crop_n_layers=1,
            crop_overlap_ratio=0.5,
            crop_nms_thresh=0.7,
            crop_n_points_downscale_factor=2,
            min_mask_region_area=80,
            output_mode="binary_mask",
        )
    elif profile.upper() == "ULTRA":
        return SamAutomaticMaskGenerator(
            model=sam,
            points_per_side=32,
            points_per_batch=128,
            pred_iou_thresh=0.94,
            stability_score_thresh=0.94,
            stability_score_offset=0.95,
            box_nms_thresh=0.7,
            crop_n_layers=2,
            crop_overlap_ratio=0.55,
            crop_nms_thresh=0.7,
            crop_n_points_downscale_factor=2,
            min_mask_region_area=40,
            output_mode="binary_mask",
        )
    else:
        raise ValueError("Unknown profile")

# current_profile = "QUALITY"
current_profile = "ULTRA"
mask_generator = make_mask_generator(current_profile)

def print_current_params():
    mg = mask_generator
    attrs = {
        "profile": current_profile,
        "points_per_side": mg.points_per_side,
        "points_per_batch": mg.points_per_batch,
        "pred_iou_thresh": mg.pred_iou_thresh,
        "stability_score_thresh": mg.stability_score_thresh,
        "stability_score_offset": mg.stability_score_offset,
        "box_nms_thresh": mg.box_nms_thresh,
        "crop_n_layers": mg.crop_n_layers,
        "crop_overlap_ratio": mg.crop_overlap_ratio,
        "crop_nms_thresh": mg.crop_nms_thresh,
        "crop_n_points_downscale_factor": mg.crop_n_points_downscale_factor,
        "min_mask_region_area": mg.min_mask_region_area,
        "output_mode": mg.output_mode,
    }
    print("üîß SAM params:", attrs)

# ====== TR·∫†NG TH√ÅI UI ======
points, labels = [], []
overlay = bgr.copy()
mask_best = None
score_best = None
all_masks = []   # danh s√°ch mask auto
WIN_NAME = "SAM (L=FG, R=BG | Enter=Run | A=Auto | M=Multi-mask | T=Text | R=Reset | S=Save | Q/U profile | Esc=Quit)"

def redraw():
    global overlay
    display = bgr.copy()
    if mask_best is not None:
        alpha = 0.45
        color = np.array([255, 0, 255], dtype=np.uint8)
        m = mask_best.astype(bool)
        display[m] = (alpha * color + (1 - alpha) * display[m]).astype(np.uint8)
        if score_best is not None:
            cv2.putText(display, f"Score: {score_best:.3f}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (50, 200, 50), 3)
    for (x, y), lb in zip(points, labels):
        if lb == 1:
            cv2.circle(display, (x, y), 5, (0, 255, 0), -1)
        else:
            cv2.drawMarker(display, (x, y), (0, 0, 255),
                           markerType=cv2.MARKER_TILTED_CROSS, markerSize=12, thickness=2)
    overlay[:] = display

def run_sam_interactive():
    global mask_best, score_best
    if len(points) == 0:
        print("‚ö†Ô∏è Ch∆∞a c√≥ ƒëi·ªÉm. Click chu·ªôt ƒë·ªÉ th√™m.")
        return
    pt = np.array(points, dtype=np.float32)
    lb = np.array(labels, dtype=np.int32)
    masks, scores, _ = predictor.predict(
        point_coords=pt,
        point_labels=lb,
        multimask_output=True,
    )
    idx = int(np.argmax(scores))
    mask_best = masks[idx]
    score_best = float(scores[idx])
    print(f"‚úÖ SAM Interactive: best score={score_best:.3f}, candidates={len(scores)}")

def run_sam_auto():
    global mask_best, score_best
    print("üöÄ SAM Auto (1 mask l·ªõn nh·∫•t)...")
    masks = mask_generator.generate(img)
    if len(masks) == 0:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y mask n√†o.")
        return
    largest = max(masks, key=lambda x: x['area'])
    mask_best = largest['segmentation']
    score_best = largest.get('stability_score', None)
    print(f"‚úÖ SAM Auto: l·∫•y mask l·ªõn nh·∫•t, area={largest['area']}")

def run_sam_auto_all():
    global all_masks
    print("üöÄ SAM Auto (nhi·ªÅu mask)...")
    all_masks = mask_generator.generate(img)
    if len(all_masks) == 0:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y mask n√†o.")
        return

    os.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)  # ƒë·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i

    display = bgr.copy()
    for m in all_masks:
        color = np.random.randint(0, 255, (3,), dtype=np.uint8)
        alpha = 0.5
        region = m["segmentation"].astype(bool)
        display[region] = (alpha * color + (1 - alpha) * display[region]).astype(np.uint8)
    cv2.imshow("All Masks", display)

    # l∆∞u overlay t·ªïng h·ª£p
    base = os.path.splitext(os.path.basename(image_path))[0]
    overlay_path = os.path.join(DEFAULT_SAVE_DIR, f"{base}_all_masks_overlay.png")
    cv2.imwrite(overlay_path, display)
    print(f"‚úÖ ƒê√£ l∆∞u {overlay_path} v·ªõi {len(all_masks)} mask")

    # l∆∞u t·ª´ng mask nh·ªã ph√¢n
    for i, m in enumerate(all_masks):
        mask = (m["segmentation"].astype(np.uint8) * 255)
        out_path = os.path.join(DEFAULT_SAVE_DIR, f"{base}_mask_{i+1:02d}.png")
        cv2.imwrite(out_path, mask)
    print(f"üíæ ƒê√£ l∆∞u {len(all_masks)} mask nh·ªã ph√¢n v√†o {DEFAULT_SAVE_DIR}")

def reset_points():
    global points, labels, mask_best, score_best, all_masks
    points.clear(); labels.clear()
    mask_best = None; score_best = None
    all_masks = []
    print("üîÑ Reset points & masks.")

def mouse_cb(event, x, y, flags, param):
    global mask_best, score_best
    if event == cv2.EVENT_LBUTTONDOWN:
        if len(all_masks) > 0:
            for m in all_masks:
                if m["segmentation"][y, x]:
                    mask_best = m["segmentation"]
                    score_best = m.get("stability_score", None)
                    print(f"üéØ Ch·ªçn mask area={m['area']}, stability={score_best}")
                    redraw()
                    return
        else:
            points.append([x, y]); labels.append(1)
            print(f"‚ûï FG: ({x},{y})"); redraw()
    elif event == cv2.EVENT_RBUTTONDOWN:
        points.append([x, y]); labels.append(0)
        print(f"‚ûï BG: ({x},{y})"); redraw()

# ====== GROUNDINGDINO: TEXT -> BOXES ======
from transformers import AutoProcessor, GroundingDinoForObjectDetection
from PIL import Image

processor = AutoProcessor.from_pretrained(GDINO_MODEL_ID)
gdino = GroundingDinoForObjectDetection.from_pretrained(GDINO_MODEL_ID)
gdino.to(device)
gdino.eval()

def run_text_boxes(pil_image, text_queries, box_threshold=0.25, text_threshold=0.25):
    """
    Tr·∫£ v·ªÅ list dict: { 'label': str, 'box_xyxy': np.ndarray(float, shape=(4,)), 'score': float }
    H·ªó tr·ª£ c√°c phi√™n b·∫£n transformers 4.39‚Äì4.42 v·ªõi API post_process_grounded_object_detection.
    """
    results_all = []
    W, H = pil_image.size

    # Gom c√°c query th√†nh 1 c√¢u, GroundingDINO s·∫Ω t·ª± matching
    caption = ". ".join(text_queries)

    with torch.no_grad():
        inputs = processor(images=pil_image, text=caption, return_tensors="pt").to(device)
        outputs = gdino(**inputs)

        # API ƒë√∫ng: post_process_grounded_object_detection(outputs, input_ids, box_threshold, text_threshold, target_sizes)
        target_sizes = torch.tensor([[H, W]], device=device)
        processed = processor.post_process_grounded_object_detection(
            outputs=outputs,
            input_ids=inputs["input_ids"],
            box_threshold=box_threshold,
            text_threshold=text_threshold,
            target_sizes=target_sizes
        )

    if len(processed) == 0:
        return results_all
    p = processed[0]
    boxes = p["boxes"].detach().cpu().numpy()     # (N, 4) xyxy theo k√≠ch th∆∞·ªõc ·∫£nh
    scores = p["scores"].detach().cpu().numpy()   # (N,)
    labels = p["labels"]                           # list[str]

    for b, s, lab in zip(boxes, scores, labels):
        results_all.append({
            "label": lab,
            "box_xyxy": b.astype(np.float32),
            "score": float(s)
        })
    return results_all

# ====== TEXT->BOX->SAM ======
def run_text_then_sam(text_queries=None, save_dir=DEFAULT_SAVE_DIR):
    """
    1) GroundingDINO t√¨m bbox theo text
    2) D√πng SAM c·∫Øt mask t·ª´ bbox (chu·∫©n SAM: xyxy theo ·∫£nh g·ªëc)
    3) L∆∞u overlay & t·ª´ng mask theo nh√£n
    """
    global mask_best, score_best, overlay

    if text_queries is None:
        text_queries = TEXT_QUERIES

    os.makedirs(save_dir, exist_ok=True)
    pil_img = Image.fromarray(img)

    print(f"üìù Text prompts: {text_queries}")
    dets = run_text_boxes(pil_img, text_queries, BOX_THRESHOLD, TEXT_THRESHOLD)
    if len(dets) == 0:
        print("‚ö†Ô∏è GroundingDINO kh√¥ng t√¨m th·∫•y ƒë·ªëi t∆∞·ª£ng ph√π h·ª£p.")
        return

    # V·∫Ω bbox l√™n ·∫£nh hi·ªÉn th·ªã, ƒë·ªìng th·ªùi g·ªçi SAM theo t·ª´ng box
    disp = bgr.copy()
    base = os.path.splitext(os.path.basename(image_path))[0]

    per_label_count = {}

    for i, det in enumerate(dets, 1):
        x1, y1, x2, y2 = det["box_xyxy"]
        label = det["label"]
        score = det["score"]

        # V·∫Ω box
        cv2.rectangle(disp, (int(x1), int(y1)), (int(x2), int(y2)), (0, 200, 255), 2)
        cv2.putText(disp, f"{label} {score:.2f}", (int(x1), int(max(0, y1-5))),
                    cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 200, 255), 3)

        # SAM t·ª´ box: predictor.predict nh·∫≠n box ·ªü to·∫° ƒë·ªô ·∫£nh g·ªëc, ƒë·ªãnh d·∫°ng XYXY
        input_box = np.array([[x1, y1, x2, y2]], dtype=np.float32)
        masks, scores, _ = predictor.predict(
            box=input_box,
            multimask_output=True,
        )
        idx = int(np.argmax(scores))
        chosen_mask = masks[idx].astype(np.uint8)  # (H,W) 0/1

        # T√¥ m√†u overlay ri√™ng theo mask
        color = np.random.randint(0, 255, (3,), dtype=np.uint8)
        mbool = chosen_mask.astype(bool)
        disp[mbool] = (0.45 * color + 0.55 * disp[mbool]).astype(np.uint8)

        # L∆∞u mask ri√™ng theo nh√£n
        per_label_count[label] = per_label_count.get(label, 0) + 1
        out_mask = (chosen_mask * 255)
        out_path = os.path.join(save_dir, f"{base}_{label}_{per_label_count[label]:02d}.png")
        cv2.imwrite(out_path, out_mask)

        # Ghi nh·ªõ mask cu·ªëi c√πng ƒë·ªÉ hi·ªÉn th·ªã ·ªü c·ª≠a s·ªï ch√≠nh
        mask_best = chosen_mask
        score_best = float(np.max(scores))

    # L∆∞u t·ªïng h·ª£p
    out_overlay = os.path.join(save_dir, f"{base}_gdino_sam_overlay.png")
    cv2.imwrite(out_overlay, disp)
    overlay[:] = disp
    print(f"‚úÖ Text‚ÜíBox‚ÜíSAM xong. ƒê√£ l∆∞u overlay: {out_overlay}")
    print("üì¶ L∆∞u t·ª´ng mask theo nh√£n trong th∆∞ m·ª•c:", save_dir)

# ====== H∆Ø·ªöNG D·∫™N UI ======
redraw()
cv2.namedWindow(WIN_NAME, cv2.WINDOW_NORMAL)
cv2.setMouseCallback(WIN_NAME, mouse_cb)

print("üëâ H∆∞·ªõng d·∫´n:")
print(" - Chu·ªôt tr√°i: Foreground (xanh) ho·∫∑c ch·ªçn mask n·∫øu ƒë√£ b·∫•m M")
print(" - Chu·ªôt ph·∫£i: Background (ƒë·ªè)")
print(" - Enter: SAM Interactive (click)")
print(" - A: SAM Auto (mask l·ªõn nh·∫•t)")
print(" - M: SAM Auto (nhi·ªÅu mask) + click ch·ªçn")
print(" - T: Text‚ÜíBox‚ÜíSAM (GroundingDINO + SAM) v·ªõi prompts:", TEXT_QUERIES)
print(" - R: reset")
print(" - S: l∆∞u mask PNG (mask hi·ªán t·∫°i + overlay hi·ªán t·∫°i v√†o th∆∞ m·ª•c GDINO_SAM c·∫°nh ·∫£nh)")
print(" - Q: QUALITY profile | U: ULTRA profile | P: in th√¥ng s·ªë hi·ªán t·∫°i")
print(" - Esc: tho√°t")

while True:
    cv2.imshow(WIN_NAME, overlay)
    k = cv2.waitKey(20) & 0xFF
    if k == 27:   # Esc
        break
    elif k == 13:  # Enter
        run_sam_interactive(); redraw()
    elif k in (ord('a'), ord('A')):
        run_sam_auto(); redraw()
    elif k in (ord('m'), ord('M')):
        run_sam_auto_all()
    elif k in (ord('t'), ord('T')):
        # C√≥ th·ªÉ ch·ªânh TEXT_QUERIES ngay trong script
        run_text_then_sam(TEXT_QUERIES); redraw()
    elif k in (ord('r'), ord('R')):
        reset_points(); redraw()
    elif k in (ord('s'), ord('S')):
        if mask_best is not None:
            os.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)
            base = os.path.splitext(os.path.basename(image_path))[0]
            mask_path = os.path.join(DEFAULT_SAVE_DIR, f"{base}_mask.png")
            overlay_path = os.path.join(DEFAULT_SAVE_DIR, f"{base}_overlay.png")
            cv2.imwrite(mask_path, (mask_best.astype(np.uint8) * 255))
            cv2.imwrite(overlay_path, overlay)
            print(f"üíæ Saved: {mask_path} + {overlay_path}")
        else:
            print("‚ö†Ô∏è Ch∆∞a c√≥ mask n√†o ƒë·ªÉ l∆∞u.")
    elif k in (ord('q'), ord('Q')):
        current_profile = "QUALITY"
        mask_generator = make_mask_generator(current_profile)
        print("‚úÖ Switched to QUALITY profile")
        print_current_params()
    elif k in (ord('u'), ord('U')):
        current_profile = "ULTRA"
        mask_generator = make_mask_generator(current_profile)
        print("‚úÖ Switched to ULTRA profile")
        print_current_params()
    elif k in (ord('p'), ord('P')):
        print_current_params()

cv2.destroyAllWindows()
